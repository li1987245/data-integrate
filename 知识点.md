### hadoop
- counter
```
2019-02-04 15:58:46,004 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=653050
		FILE: Number of bytes written=1749879
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=618040
		HDFS: Number of bytes written=624269
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=5408
		Total time spent by all reduces in occupied slots (ms)=6540
		Total time spent by all map tasks (ms)=2704
		Total time spent by all reduce tasks (ms)=3270
		Total vcore-milliseconds taken by all map tasks=2704
		Total vcore-milliseconds taken by all reduce tasks=3270
		Total megabyte-milliseconds taken by all map tasks=1384448
		Total megabyte-milliseconds taken by all reduce tasks=1674240
	Map-Reduce Framework
		Map input records=4058
		Map output records=5533
		Map output bytes=639356
		Map output materialized bytes=653050
		Input split bytes=116
		Combine input records=5533
		Combine output records=5502
		Reduce input groups=5502
		Reduce shuffle bytes=653050
		Reduce input records=5502
		Reduce output records=5502
		Spilled Records=11004
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=132
		CPU time spent (ms)=1720
		Physical memory (bytes) snapshot=535298048
		Virtual memory (bytes) snapshot=4670066688
		Total committed heap usage (bytes)=406323200
		Peak Map Physical memory (bytes)=296005632
		Peak Map Virtual memory (bytes)=2333917184
		Peak Reduce Physical memory (bytes)=239292416
		Peak Reduce Virtual memory (bytes)=2336149504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters
		Bytes Read=617924
	File Output Format Counters
		Bytes Written=624269
```
### yarn


### hive
#### DDL
- 创建
```
CREATE EXTERNAL TABLE ods.user (
  user_num STRING COMMENT '用户编号',
  mobile STRING COMMENT '手机号码',
  reg_date STRING COMMENT '注册日期'
COMMENT '用户资料表'
PARTITIONED BY (dt string)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' LINES TERMINATED BY '\n'
STORED AS ORC
LOCATION '/ods/user';
)
```
#### 拉链表
- 概念
```
通过数据结束时间来确定数据是否为最新记录，默认结束时间为最大时间，如果数据有修改，设置数据结束时间为修改时间，修改后数据的新增时间为修改时间，结束时间为最大时间
```
- 应用场景
```
在数据仓库的数据模型设计过程中，经常会遇到下面这种表的设计：

有一些表的数据量很大，比如一张用户表，大约10亿条记录，50个字段，这种表，即使使用ORC压缩，单张表的存储也会超过100G，在HDFS使用双备份或者三备份的话就更大一些。
表中的部分字段会被update更新操作，如用户联系方式，产品的描述信息，订单的状态等等。
需要查看某一个时间点或者时间段的历史快照信息，比如，查看某一个订单在历史某一个时间点的状态。
表中的记录变化的比例和频率不是很大，比如，总共有10亿的用户，每天新增和发生变化的有200万左右，变化的比例占的很小。
那么对于这种表我该如何设计呢？下面有几种方案可选：

方案一：每天只留最新的一份，比如我们每天用Sqoop抽取最新的一份全量数据到Hive中。
方案二：每天保留一份全量的切片数据。
方案三：使用拉链表。
```
- 设计和实现
```
1. ODS层原始切片表（按天分区，包含更新时间）
2. 加工更新表（包含新增和被修改的数据）
3. INSERT OVERWRITE TABLE dws.table
   SELECT * FROM
   (
       SELECT A.user_num,
              A.mobile,
              A.reg_date,
              A.t_start_time,
              CASE
                   WHEN A.t_end_time = '9999-12-31' AND B.user_num IS NOT NULL THEN '2017-01-01'
                   ELSE A.t_end_time
              END AS t_end_time
       FROM dws.user_his AS A
       LEFT JOIN ods.user_update AS B
       ON A.user_num = B.user_num
   UNION
       SELECT C.user_num,
              C.mobile,
              C.reg_date,
              '2017-01-02' AS t_start_time,
              '9999-12-31' AS t_end_time
       FROM ods.user_update AS C
   ) AS T
```
- 冷热数据分离
```
因为拉链表会保存历史全量变更，数据量会不断增加，可以抽取最近一段时间的变更数据供后面使用
```

### hbase

- Phoenix

### spark
- scala match
- scala容器

- scala隐式转换
```
1.隐式参数
隐式参数列表，置于方法的最后一个参数列表，方法有多个隐式参数，只需一个implicit修饰即可，def foo(n: Int)(implicit t1: String, t2: Double = 3.14)。
当调用包含隐式参数的方法时，自动在当前上下文中查找合适的隐式值
2.隐式地转换类型
使用隐含转换将变量转换成预期的类型
3.隐式调用函数
隐式调用函数可以转换调用方法的对象，比如但编译器看到X .method，而类型 X 没有定义 method（包括基类)方法，那么编译器就查找作用域内定义的从 X 到其它对象的类型转换
```
- scala偏函数

- scala特质

- spark rdd dataframe dataset区别和转换

- spark shuffle stage
```
reduceByKey、groupByKey、countByKey、join等操作会产生shuffle
# 开启map端输出文件合并
spark.shuffle.consolidateFiles # 默认为false，设置为true，那么就会开启consolidate机制，会大幅度合并shuffle write的输出文件
new SparkConf().set("spark.shuffle.consolidateFiles", "true")
# shuffle缓存调整
spark.shuffle.file.buffer # 设置shuffle write task的BufferedOutputStream的buffer缓冲大小，默认32k
spark.reducer.maxSizeInFlight # 设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据
spark.shuffle.memoryFraction # 设置Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是0.2
spark.shuffle.manager # 默认值：sort，设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。
                        通过bypass机制（spark.shuffle.sort.bypassMergeThreshold大于shuffle read task的数量。那么此时就会自动启用bypass机制）或优化的HashShuffleManager来避免排序操作
```
- spark常用算子
map flatmap

-spark partition

- spark-submit 调优参数

- spark 内存溢出

- spark cache persist

- spark数据倾斜


### Storm
https://blog.csdn.net/vim_wj/article/details/75831677
### impala

### kafka


### zookeeper


### elasticsearch


### flume


### ranger


### Flink


### Kylin

### MQ
#### rabbitMQ
a)消费者是无法订阅或者获取不存在的MessageQueue中信息。
b)消息被Exchange接受以后，如果没有匹配的Queue，则会被丢弃。
- exchange
```
Exchange是接受生产者消息并将消息路由到消息队列的关键组件。ExchangeType和Binding决定了消息的路由规则。所以生产者想要发送消息，首先必须要声明一个Exchange和该Exchange对应的Binding。
可以通过 ExchangeDeclare和BindingDeclare完成。在Rabbit MQ中，声明一个Exchange需要三个参数：ExchangeName，ExchangeType和Durable。
ExchangeName是该Exchange的名字，该属性在创建Binding和生产者通过publish推送消息时需要指定。ExchangeType，指Exchange的类型，在RabbitMQ中，有三种类型的Exchange：direct ，fanout和topic，不同的Exchange会表现出不同路由行为。
Direct类型，则会将消息中的RoutingKey与该Exchange关联的所有Binding中的BindingKey进行比较，如果相等，则发送到该Binding对应的Queue中。
Fanout  类型，则会将消息发送给所有与该  Exchange  定义过  Binding  的所有  Queues  中去，其实是一种广播行为。
Topic类型，则会按照正则表达式，对RoutingKey(生产者)与BindingKey(bind指定)进行匹配，如果匹配成功，则发送到对应的Queue中。
```
- Binding
```
声明一个Binding需要提供一个QueueName，ExchangeName和BindingKey。
```
- queue


### java
- 集合

- 高并发


- 垃圾收集

- ClassLoader
```
两种方法分别是：
1. java -Xbootclasspath/a:/etc/hadoop/conf:/etc/hive/conf -jar example.jar
2. java -cp /etc/hadoop/conf:/etc/hive/conf:./example.jar example.Main.class
注意事项：
（1）-Xbootclasspath/a:要在-jar之前
（2）-Xbootclasspath/a:和后面的参数之间不能有空格
（3）example.Main.class是jar包的主类，要把相应的jar包放到classpath参数中。
（4）文件路径之间使用分隔符（win下为分号，linux下为冒号）

```

- maven
# -pl指定打包模块  -am同时install依赖
mvn clean install -Dmaven.test.skip=true -pl data-insight-manage -am
mvn clean install -Dmaven.test.skip=true -rf data-insight-manage
安装maven helper 插件，在pom.xml文件下点击dependency Analyzer分析查看冲突的包
```
双亲委派
web容器需要自定义classloader，实现不同项目之间class隔离
```
- 内存模型

- nio
FileLock实现不同jvm进程之间的文件锁，不能实现同一jvm多线程文件锁，同jvm多线程会抛java.nio.channels.OverlappingFileLockException异常
WatchService监控文件
### netty


### spring cloud

- bean初始化顺序
```
一，单一Bean
装载
1. 实例化; 
2. 设置属性值; 
3. 如果实现了BeanNameAware接口,调用setBeanName设置Bean的ID或者Name; 
4. 如果实现BeanFactoryAware接口,调用setBeanFactory 设置BeanFactory; 
5. 如果实现ApplicationContextAware,调用setApplicationContext设置ApplicationContext 
6. 调用BeanPostProcessor的预先初始化方法; 
7. 调用InitializingBean的afterPropertiesSet()方法; 
8. 调用定制init-method方法； 
9. 调用BeanPostProcessor的后初始化方法;
spring容器关闭
1. 调用DisposableBean的destroy(); 
2. 调用定制的destroy-method方法;
 
二，多个Bean的先后顺序
优先加载BeanPostProcessor的实现Bean
按Bean文件和Bean的定义顺序按bean的装载顺序（即使加载多个spring文件时存在id覆盖）
“设置属性值”（第2步）时，遇到ref，则在“实例化”（第1步）之后先加载ref的id对应的bean
AbstractFactoryBean的子类，在第6步之后,会调用createInstance方法，之后会调用getObjectType方法
BeanFactoryUtils类也会改变Bean的加载顺序
```
- applicationcontextaware
```
可以获得ApplicationContext
```
- ApplicationContext
```
getbean
getEnvironment
```
- ApplicationListener
```
实现ApplicationEvent接口定义事件，实现ApplicationListener监听自定义事件
```
- InitializingBean
```
当需要在bean的全部属性设置成功后做些特殊的处理，可以让该bean实现InitializingBean接口,效果等同于bean的init-method属性的使用或者@PostContsuct注解的使用。       
三种方式的执行顺序：先注解，然后执行InitializingBean接口中定义的方法，最后执行init-method属性指定的方法。
```
- BeanPostProcessor
```
需要对受管bean进行预处理时，可以新建一个实现BeanPostProcessor接口的类
实现BeanPostProcessor接口时，需要实现以下两个方法：
postProcessBeforeInitialization 在受管bean的初始化动作之前调用
postProcessAfterInitialization 在受管bean的初始化动作之后调用容器中的每个Bean在创建时都会恰当地调用它们
```
- InstantiationAwareBeanPostProcessorAdapter
```
InstantiationAwareBeanPostProcessor 接口本质是BeanPostProcessor的子接口，一般我们继承Spring为其提供的适配器类InstantiationAwareBeanPostProcessorAdapter来使用
```
- BeanFactoryPostProcessor
```
需要对Bean工厂进行预处理时，可以新建一个实现BeanFactoryPostProcessor接口的类，可以同时实现EnvironmentAware获得environment
public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException {

}
```
- ClassPathBeanDefinitionScanner
```
在IOC 容器初始化阶段（调用beanFactoryPostProcessor阶段） 就会采用ClassPathBeanDefinitionScanner进行扫描包下 所有类，并将符合过滤条件的类注册到IOC 容器内
```
- ResourceBundleMessageSource
```
提供国际化支持，bean的名字必须为messageSource
```
- FactoryBean
```
```
- BeanFactory
```
```
- ApplicationContextInitializer
```
实现接口获得ConfigurableApplicationContext
ApplicationContextInitializer是一个回调接口，它会在ConfigurableApplicationContext的refresh()方法调用之前被调用,做一些容器的初始化工作。
1.
SpringApplication springApplication = new SpringApplication(DemoApplication.class);
springApplication.addInitializers(new DemoApplicationContextInitializer());
springApplication.run(args);
2.多个逗号分隔
META-INF/spring.factories文件增加org.springframework.context.ApplicationContextInitializer=example.demo.DemoApplicationContextInitializer
3.多个逗号分隔
application.properties增加context.initializer.classes=example.demo.DemoApplicationContextInitializer
```
- ConfigurableApplicationContext
```
extends ApplicationContext, Lifecycle, Closeable
addBeanFactoryPostProcessor
getBeanFactory:ConfigurableListableBeanFactory,ConfigurableListableBeanFactory可以注册bean
```
- BeanUtils
```
实例化类
```
![流程图](http://img.my.csdn.net/uploads/201304/13/1365825529_4693.png)
![时序图](http://img.my.csdn.net/uploads/201304/13/1365825551_8302.png)

- HandlerMethodArgumentResolver
```
@RequestParam、@RequestHeader、@RequestBody、@PathVariable、@ModelAttribute
参数解析接口
```
- HandlerMethodReturnValueHandler
```
结果封装接口
```
RequestResponseBodyMethodProcessor
```
实现HandlerMethodReturnValueHandler，@ResponseBody处理类
```

- RequestMappingHandlerAdapter
```
持有HandlerMethodArgumentResolver集合，进行请求参数映射
持有HandlerMethodReturnValueHandler集合，进行结果封装
持有HttpMessageConverter集合，进行转换
持有ModelAndViewResolver集合，负责定制返回类型
```
- WebMvcConfigurerAdapter
```
添加拦截器、消息转换、controller...
```
- HttpMessageConverter
```
消息装换，通过canread和canwrite来处理对应消息格式
```
AbstractHttpMessageConverter
```
HttpMessageConverter代理类
```
MappingJackson2HttpMessageConverter
```
json转换
```
HttpServletRequestWrapper 
```
通过对HttpServletRequest的封装，解决HttpServletRequest对象不可变的情况，通过在filter中对HttpServletRequest进行处理来解决参数问题
```

RequestContextHolder
```
获取ServletRequestAttributes,然后获取request、response
```

- FilterRegistrationBean
```
@bean注解方式增加过滤器
```
- dubbo


### k8s+docker
- docker文章
```
http://www.cnblogs.com/SzeCheng/p/6822905.html
```
- Dockerfile配置
1.vim Dockerfile
```
FROM centos:6
# ADD可以自动解压缩
ADD jdk1.8.tar.gz /opt/
ENV JAVA_HOME=
ENV CLASS_PATH=.:$JAVA_HOME/lib:$CLASS_PATH \
PATH=$JAVA_HOME/bin:$PATH
ENV LANG en_US.utf8
```
2.docker build -t jdk:8 -f Dockerfile .

- docker 常用操作
```
# 启动新容器
docker run -itd --name jdk jdk:8 /bin/bash
docker run --name web2 -d -p 81:80 nginx:v2
# 进入运行中的容器
docker exec -it jdk bash
# 停止后台容器
docker container ls -a
docker container stop jdk
# 重启已停止容器
docker container start jdk
# 删除容器
docker container rm jdk
```
- docker安装
```

```

- k8s 组件
```
Delpoyment:
管理rs
ReplicaSet(rs)：
管理pod
Pod：
集群管理最小单位
Service：
逻辑pod组，为一组相同label的pod集合
```

- k8s 常用操作
```
kubectl cluster-info #查询k8s集群信息
kubectl -s http://localhost:8080 get componentstatuses  #查看各组件状态
kubectl get nodes #查看节点
kubectl get rc,namespace #查看rc和namespace
kubectl get pods,svc --all-namespaces #查看pod和svc
kubectl get po mysql -o json #以json格式输出pod的详细信息
kubectl get po mysql -o wide  #查看指定pod跑在哪个node上
kubectl describe pod data-insight-auth-d5cc58f4f-54k7b #查询pod状态信息
kubectl create -f filename #创建文件内定义的resource
kubectl replace -f rc-nginx.yaml #对已有资源进行更新、替换
kubectl edit po mysql #编辑现有的resource
kubectl delete -f rc-nginx.yaml/kubectl delete po rc-nginx-btv4j #删除现有资源
kubectl logs rc-nginx-2-kpiqt #打印容器内程序输出到标准输出的内容
kubectl rolling-update rc-nginx-2 -f rc-nginx.yaml #滚动升级
kubectl scale rc rc-nginx-3 —replicas=4 #调整实例数量
kubectl autoscale rc rc-nginx-3 —min=1 —max=4 #动态调整实例数量
kubectl attach kube-dns-v9-rcfuk -c skydns —namespace=kube-system #直接查看容器中以daemon形式运行的进程的输出，有多个容器，需要使用-c选项指定容器
kubectl exec #类似于docker的exec命令，有多个容器，需要使用-c选项指定容器

```

### mybatis

- 拦截器


#### 算法
- 图

- bitmap

- hash

- 树

- 排序

- 背包

### redis
- redis value size
```
通信缓冲区的最终限制。
当GET命令应用于大对象时，首先序列化该对象
在通信缓冲区中，然后写入客户端套接字。
最理想的情况是在一个以太网数据（1500byte）包内传输
```
### mysql
#### Canal日志同步

### 缓存
