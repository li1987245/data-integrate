### hadoop
#### hdfs
##### NameNode
- 文件结构
edits、fsimage、seen_txid、VERSION
1.edits
编辑日志（edit log）：当客户端执行写操作时，首先NameNode会在编辑日志中写下记录，并在内存中保存一个文件系统元数据，这个描述符会在编辑日志改动之后更新。
edits_start transaction ID-end transaction ID
finalized edit log segments，在HA（高可用）环境中，Standby Namenode只能读取finalized log segments，
edits_inprogress__start transaction ID
当前正在被追加的edit log，HDFS默认会为该文件提前申请1MB空间以提升性能
2.fsimage
文件系统镜像（fsimage）:文件系统元数据的持久检查点，包含以序列化格式（从Hadoop-2.4.0起，FSImage开始采用Google Protobuf编码格式）存储的文件系统目录和文件inodes，每个inodes表征一个文件或目录的元数据信息以及文件的副本数、修改和访问时间等信息。
fsimage_end transaction ID
每次checkpoing（合并所有edits到一个fsimage的过程）产生的最终的fsimage，同时会生成一个.md5的文件用来对文件做完整性校验
3.seen_txid
seen_txid是存放transactionId的文件，format之后是0，它代表的是namenode里面的edits_*文件的尾数，namenode重启的时候，会按照seen_txid的数字，循序从头跑edits_0000001~到seen_txid的数字
4.VERSION
VERSION文件是java属性文件，保存了HDFS的版本号
• namespaceID是文件系统的唯一标识符，是在文件系统初次格式化时生成的。
• clusterID是系统生成或手动指定的集群ID
• cTime表示NameNode存储时间的创建时间，升级后会更新该值。
• storageType表示此文件夹中保存的是元数据节点的数据结构。
• blockpoolID：针对每一个Namespace所对应blockpool的ID,该ID包括了其对应的NameNode节点的ip地址。
• layoutVersion是一个负整数，保存了HDFS的持续化在硬盘上的数据结构的格式版本号。
5.in_use.lock
防止一台机器同时启动多个Namenode进程导致目录数据不一致
6.namenode同步：
1）Secondary NameNode首先请求原NameNode进行edits的滚动，这样新的编辑操作就能够进入新的文件中。

2）Secondary NameNode通过HTTP方式读取原NameNode中的fsimage及edits。

3）Secondary NameNode读取fsimage到内存中，然后执行edits中的每个操作，并创建一个新的统一的fsimage文件。

4）Secondary NameNode通过HTTP方式将新的fsimage发送到原NameNode。

5）原NameNode用新的fsimage替换旧的fsimage，旧的edits文件用步骤1）中的edits进行替换（将edits.new改名为edits）。同时系统会更新fsimage文件到记录检查点的时间。
这个过程结束后，NameNode就有了最新的fsimage文件和更小的edits文件

注：可执行hadoop dfsadmin –saveNamespace命令运行上图的过程Secondary NameNode（NameNode的冷备份）每隔一小时会插入一个检查点，如果编辑日志达到64MB，则间隔时间更短，每隔5分钟检查一次。
https://blog.csdn.net/baiye_xing/article/details/76268495
##### DataNode
DataNode的文件结构主要由blk_前缀文件、BP-random integer-NameNode-IP address-creation time和VERSION构成
1.BP-random integer-NameNode-IP address-creation time
BP代表BlockPool的，就是Namenode的VERSION中的集群唯一blockpoolID
2.finalized/rbw
这两个目录都是用于实际存储HDFS BLOCK的数据，里面包含许多block_xx文件以及相应的.meta文件，.meta文件包含了checksum信息。
rbw是“replica being written”的意思，该目录用于存储用户当前正在写入的数据。
3.blk_前缀文件
HDFS中的文件块本身，存储的是原始文件内容。
块的元数据信息（使用.meta后缀标识）。一个文件块由存储的原始文件字节组成，元数据文件由一个包含版本和类型信息的头文件和一系列块的区域校验和组成。

- counter
```
2019-02-04 15:58:46,004 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=653050
		FILE: Number of bytes written=1749879
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=618040
		HDFS: Number of bytes written=624269
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=5408
		Total time spent by all reduces in occupied slots (ms)=6540
		Total time spent by all map tasks (ms)=2704
		Total time spent by all reduce tasks (ms)=3270
		Total vcore-milliseconds taken by all map tasks=2704
		Total vcore-milliseconds taken by all reduce tasks=3270
		Total megabyte-milliseconds taken by all map tasks=1384448
		Total megabyte-milliseconds taken by all reduce tasks=1674240
	Map-Reduce Framework
		Map input records=4058
		Map output records=5533
		Map output bytes=639356
		Map output materialized bytes=653050
		Input split bytes=116
		Combine input records=5533
		Combine output records=5502
		Reduce input groups=5502
		Reduce shuffle bytes=653050
		Reduce input records=5502
		Reduce output records=5502
		Spilled Records=11004
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=132
		CPU time spent (ms)=1720
		Physical memory (bytes) snapshot=535298048
		Virtual memory (bytes) snapshot=4670066688
		Total committed heap usage (bytes)=406323200
		Peak Map Physical memory (bytes)=296005632
		Peak Map Virtual memory (bytes)=2333917184
		Peak Reduce Physical memory (bytes)=239292416
		Peak Reduce Virtual memory (bytes)=2336149504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters
		Bytes Read=617924
	File Output Format Counters
		Bytes Written=624269
```
### yarn


### hive
#### DDL
- 创建
```
CREATE EXTERNAL TABLE ods.user (
  user_num STRING COMMENT '用户编号',
  mobile STRING COMMENT '手机号码',
  reg_date STRING COMMENT '注册日期'
COMMENT '用户资料表'
PARTITIONED BY (dt string)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' LINES TERMINATED BY '\n'
STORED AS ORC
LOCATION '/ods/user';
)
```
#### 拉链表
- 概念
```
通过数据结束时间来确定数据是否为最新记录，默认结束时间为最大时间，如果数据有修改，设置数据结束时间为修改时间，修改后数据的新增时间为修改时间，结束时间为最大时间
```
- 应用场景
```
在数据仓库的数据模型设计过程中，经常会遇到下面这种表的设计：

有一些表的数据量很大，比如一张用户表，大约10亿条记录，50个字段，这种表，即使使用ORC压缩，单张表的存储也会超过100G，在HDFS使用双备份或者三备份的话就更大一些。
表中的部分字段会被update更新操作，如用户联系方式，产品的描述信息，订单的状态等等。
需要查看某一个时间点或者时间段的历史快照信息，比如，查看某一个订单在历史某一个时间点的状态。
表中的记录变化的比例和频率不是很大，比如，总共有10亿的用户，每天新增和发生变化的有200万左右，变化的比例占的很小。
那么对于这种表我该如何设计呢？下面有几种方案可选：

方案一：每天只留最新的一份，比如我们每天用Sqoop抽取最新的一份全量数据到Hive中。
方案二：每天保留一份全量的切片数据。
方案三：使用拉链表。
```
- 设计和实现
```
1. ODS层原始切片表（按天分区，包含更新时间）
2. 加工更新表（包含新增和被修改的数据）
3. INSERT OVERWRITE TABLE dws.table
   SELECT * FROM
   (
       SELECT A.user_num,
              A.mobile,
              A.reg_date,
              A.t_start_time,
              CASE
                   WHEN A.t_end_time = '9999-12-31' AND B.user_num IS NOT NULL THEN '2017-01-01'
                   ELSE A.t_end_time
              END AS t_end_time
       FROM dws.user_his AS A
       LEFT JOIN ods.user_update AS B
       ON A.user_num = B.user_num
   UNION
       SELECT C.user_num,
              C.mobile,
              C.reg_date,
              '2017-01-02' AS t_start_time,
              '9999-12-31' AS t_end_time
       FROM ods.user_update AS C
   ) AS T
```
- 冷热数据分离
```
因为拉链表会保存历史全量变更，数据量会不断增加，可以抽取最近一段时间的变更数据供后面使用
```

### hbase

- Phoenix

### spark
- scala match
- scala容器

- scala隐式转换
```
1.隐式参数
隐式参数列表，置于方法的最后一个参数列表，方法有多个隐式参数，只需一个implicit修饰即可，def foo(n: Int)(implicit t1: String, t2: Double = 3.14)。
当调用包含隐式参数的方法时，自动在当前上下文中查找合适的隐式值
2.隐式地转换类型
使用隐含转换将变量转换成预期的类型
3.隐式调用函数
隐式调用函数可以转换调用方法的对象，比如但编译器看到X .method，而类型 X 没有定义 method（包括基类)方法，那么编译器就查找作用域内定义的从 X 到其它对象的类型转换
```
- scala偏函数

- scala特质

- spark rdd dataframe dataset区别和转换

- spark shuffle stage
```
reduceByKey、groupByKey、countByKey、join等操作会产生shuffle
# 开启map端输出文件合并
spark.shuffle.consolidateFiles # 默认为false，设置为true，那么就会开启consolidate机制，会大幅度合并shuffle write的输出文件
new SparkConf().set("spark.shuffle.consolidateFiles", "true")
# shuffle缓存调整
spark.shuffle.file.buffer # 设置shuffle write task的BufferedOutputStream的buffer缓冲大小，默认32k
spark.reducer.maxSizeInFlight # 设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据
spark.shuffle.memoryFraction # 设置Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是0.2
spark.shuffle.manager # 默认值：sort，设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。
                        通过bypass机制（spark.shuffle.sort.bypassMergeThreshold大于shuffle read task的数量。那么此时就会自动启用bypass机制）或优化的HashShuffleManager来避免排序操作
```
- spark常用算子
map flatmap

-spark partition

- spark-submit 调优参数

- spark 内存溢出

- spark cache persist

- spark数据倾斜


### Storm
https://blog.csdn.net/vim_wj/article/details/75831677
### impala

### kafka


### zookeeper


### elasticsearch


### flume


### ranger


### Flink


### Kylin

### MQ
#### rabbitMQ
a)消费者是无法订阅或者获取不存在的MessageQueue中信息。
b)消息被Exchange接受以后，如果没有匹配的Queue，则会被丢弃。
- exchange
```
Exchange是接受生产者消息并将消息路由到消息队列的关键组件。ExchangeType和Binding决定了消息的路由规则。所以生产者想要发送消息，首先必须要声明一个Exchange和该Exchange对应的Binding。
可以通过 ExchangeDeclare和BindingDeclare完成。在Rabbit MQ中，声明一个Exchange需要三个参数：ExchangeName，ExchangeType和Durable。
ExchangeName是该Exchange的名字，该属性在创建Binding和生产者通过publish推送消息时需要指定。ExchangeType，指Exchange的类型，在RabbitMQ中，有三种类型的Exchange：direct ，fanout和topic，不同的Exchange会表现出不同路由行为。
Direct类型，则会将消息中的RoutingKey与该Exchange关联的所有Binding中的BindingKey进行比较，如果相等，则发送到该Binding对应的Queue中。
Fanout  类型，则会将消息发送给所有与该  Exchange  定义过  Binding  的所有  Queues  中去，其实是一种广播行为。
Topic类型，则会按照正则表达式，对RoutingKey(生产者)与BindingKey(bind指定)进行匹配，如果匹配成功，则发送到对应的Queue中。
```
- Binding
```
声明一个Binding需要提供一个QueueName，ExchangeName和BindingKey。
```
- queue


### java
- 集合

- 高并发

- IO
```
connect per reset
对端已经关闭，并返回reset后，还在读取
broken pipe
对端已经关闭，返回reset后，还在写入
```


- 垃圾收集

- ClassLoader
```
两种方法分别是：
1. java -Xbootclasspath/a:/etc/hadoop/conf:/etc/hive/conf -jar example.jar
2. java -cp /etc/hadoop/conf:/etc/hive/conf:./example.jar example.Main.class
注意事项：
（1）-Xbootclasspath/a:要在-jar之前
（2）-Xbootclasspath/a:和后面的参数之间不能有空格
（3）example.Main.class是jar包的主类，要把相应的jar包放到classpath参数中。
（4）文件路径之间使用分隔符（win下为分号，linux下为冒号）

```

- maven
# -pl指定打包模块  -am同时install依赖
mvn clean install -Dmaven.test.skip=true -pl data-insight-manage -am
mvn clean install -Dmaven.test.skip=true -rf data-insight-manage
安装maven helper 插件，在pom.xml文件下点击dependency Analyzer分析查看冲突的包
```
双亲委派
web容器需要自定义classloader，实现不同项目之间class隔离
```
- 内存模型

- nio
FileLock实现不同jvm进程之间的文件锁，不能实现同一jvm多线程文件锁，同jvm多线程会抛java.nio.channels.OverlappingFileLockException异常
WatchService监控文件
### netty


### spring cloud

![spring bean生命周期](http://dl2.iteye.com/upload/attachment/0099/3887/fbe424a3-c67a-356d-bfec-be8c030ec0a6.jpg)
- applicationcontextaware
```
可以获得ApplicationContext
```
- ApplicationContext
```
getbean
getEnvironment
```
- ApplicationListener
```
实现ApplicationEvent接口定义事件，实现ApplicationListener监听自定义事件
```
- InitializingBean
```
当需要在bean的全部属性设置成功后做些特殊的处理，可以让该bean实现InitializingBean接口,效果等同于bean的init-method属性的使用或者@PostContsuct注解的使用。       
三种方式的执行顺序：先注解，然后执行InitializingBean接口中定义的方法，最后执行init-method属性指定的方法。
```
- BeanPostProcessor
```
需要对受管bean进行预处理时，可以新建一个实现BeanPostProcessor接口的类
实现BeanPostProcessor接口时，需要实现以下两个方法：
postProcessBeforeInitialization 在受管bean的初始化动作之前调用
postProcessAfterInitialization 在受管bean的初始化动作之后调用容器中的每个Bean在创建时都会恰当地调用它们
```
- InstantiationAwareBeanPostProcessorAdapter
```
InstantiationAwareBeanPostProcessor 接口本质是BeanPostProcessor的子接口，一般我们继承Spring为其提供的适配器类InstantiationAwareBeanPostProcessorAdapter来使用
```
- BeanFactoryPostProcessor
```
需要对Bean工厂进行预处理时，可以新建一个实现BeanFactoryPostProcessor接口的类
public void postProcessBeanFactory(ConfigurableListableBeanFactory beanFactory) throws BeansException {

}
```

- ResourceBundleMessageSource
```
提供国际化支持，bean的名字必须为messageSource
```
- FactoryBean
```
```
- BeanFactory
```
```
- ApplicationContextInitializer
```
实现接口获得ConfigurableApplicationContext
```
- ConfigurableApplicationContext
```
extends ApplicationContext, Lifecycle, Closeable
addBeanFactoryPostProcessor
getBeanFactory:ConfigurableListableBeanFactory,ConfigurableListableBeanFactory可以注册bean
```
- BeanUtils
```
实例化类
```
![流程图](http://img.my.csdn.net/uploads/201304/13/1365825529_4693.png)
![时序图](http://img.my.csdn.net/uploads/201304/13/1365825551_8302.png)

- HandlerMethodArgumentResolver
```
@RequestParam、@RequestHeader、@RequestBody、@PathVariable、@ModelAttribute
参数解析接口
```
- HandlerMethodReturnValueHandler
```
结果封装接口
```
RequestResponseBodyMethodProcessor
```
实现HandlerMethodReturnValueHandler，@ResponseBody处理类
```

- RequestMappingHandlerAdapter
```
持有HandlerMethodArgumentResolver集合，进行请求参数映射
持有HandlerMethodReturnValueHandler集合，进行结果封装
持有HttpMessageConverter集合，进行转换
持有ModelAndViewResolver集合，负责定制返回类型
```
- WebMvcConfigurerAdapter
```
添加拦截器、消息转换、controller...
```
- HttpMessageConverter
```
消息装换，通过canread和canwrite来处理对应消息格式
```
AbstractHttpMessageConverter
```
HttpMessageConverter代理类
```
MappingJackson2HttpMessageConverter
```
json转换
```
HttpServletRequestWrapper 
```
通过对HttpServletRequest的封装，解决HttpServletRequest对象不可变的情况，通过在filter中对HttpServletRequest进行处理来解决参数问题
```

RequestContextHolder
```
获取ServletRequestAttributes,然后获取request、response
```

- FilterRegistrationBean
```
@bean注解方式增加过滤器
```

- dubbo


### k8s+docker
- docker文章
```
http://www.cnblogs.com/SzeCheng/p/6822905.html
```
- Dockerfile配置
1.vim Dockerfile
```
FROM centos:6
# ADD可以自动解压缩
ADD jdk1.8.tar.gz /opt/
ENV JAVA_HOME=
ENV CLASS_PATH=.:$JAVA_HOME/lib:$CLASS_PATH \
PATH=$JAVA_HOME/bin:$PATH
ENV LANG en_US.utf8
```
2.docker build -t jdk:8 -f Dockerfile .

- docker 常用操作
```
# 启动新容器
docker run -itd --name jdk jdk:8 /bin/bash
docker run --name web2 -d -p 81:80 nginx:v2
# 进入运行中的容器
docker exec -it jdk bash
# 停止后台容器
docker container ls -a
docker container stop jdk
# 重启已停止容器
docker container start jdk
# 删除容器
docker container rm jdk
```
- docker安装
```

```

- k8s 组件
```
Delpoyment:
管理rs
ReplicaSet(rs)：
管理pod
Pod：
集群管理最小单位
Service：
逻辑pod组，为一组相同label的pod集合
```

- k8s 常用操作
```
kubectl cluster-info #查询k8s集群信息
kubectl -s http://localhost:8080 get componentstatuses  #查看各组件状态
kubectl get nodes #查看节点
kubectl get rc,namespace #查看rc和namespace
kubectl get pods,svc --all-namespaces #查看pod和svc
kubectl get po mysql -o json #以json格式输出pod的详细信息
kubectl get po mysql -o wide  #查看指定pod跑在哪个node上
kubectl describe pod data-insight-auth-d5cc58f4f-54k7b #查询pod状态信息
kubectl create -f filename #创建文件内定义的resource
kubectl replace -f rc-nginx.yaml #对已有资源进行更新、替换
kubectl edit po mysql #编辑现有的resource
kubectl delete -f rc-nginx.yaml/kubectl delete po rc-nginx-btv4j #删除现有资源
kubectl logs rc-nginx-2-kpiqt #打印容器内程序输出到标准输出的内容
kubectl rolling-update rc-nginx-2 -f rc-nginx.yaml #滚动升级
kubectl scale rc rc-nginx-3 —replicas=4 #调整实例数量
kubectl autoscale rc rc-nginx-3 —min=1 —max=4 #动态调整实例数量
kubectl attach kube-dns-v9-rcfuk -c skydns —namespace=kube-system #直接查看容器中以daemon形式运行的进程的输出，有多个容器，需要使用-c选项指定容器
kubectl exec #类似于docker的exec命令，有多个容器，需要使用-c选项指定容器

```

### mybatis

- 拦截器


#### 算法
- 图

- bitmap

- hash

- 树

- 排序

- 背包

### redis
- redis value size
```
通信缓冲区的最终限制。
当GET命令应用于大对象时，首先序列化该对象
在通信缓冲区中，然后写入客户端套接字。
最理想的情况是在一个以太网数据（1500byte）包内传输
```
### mysql
- mysql 占用内存过大排查
```
1.通过show full processlist和show open tables查看当前应用的表及正在使用的sql
show global status like 'Open%tables'可以看到历史打开表数量合计（opened_tables）
2.table_open_cache控制table cache总数量
当缓冲已满，而连接想要打开一个不在缓冲中的表时。
当缓冲数目已经超过了table_open_cache设置的值，mysql开始使用LRU算法释放表对象。
当你用flush tables;语句时。
3.open_files_limit表示mysqld可用的最大文件描述符数目，在Unix系统下这个值的数目不能大于ulimit -n
4.innodb_open_files只对InnoDB存储引擎有效，它指定了mysql可以同时打开的最大.ibd文件的数目。
max_connections*你的表数目 = table_open_cache <=open_files_limit< ulimit -n
innodb_open_files<ulimit -n
5.key_buffer_size
show variables like  'key_buffer_size';
show status like 'key_read%'; //Key_read_requests和Key_reads，比例key_reads / key_read_requests应该尽可能的低
6.innodb_buffer_pool_size
缓存innodb表的索引，数据，插入数据时的缓冲
7.query_cache_size
查询缓存
8.tmp_table_size
临时表大小
9.sort_buffer_size
排序缓存
参考：
https://www.cnblogs.com/leohahah/p/8921107.html
https://www.cnblogs.com/kevingrace/p/6133818.html
```
#### Canal日志同步

### 缓存


### nginx
1. location ^~ /analysis/不生效
