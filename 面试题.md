### hadoop
- counter
```
2019-02-04 15:58:46,004 INFO mapreduce.Job: Counters: 54
	File System Counters
		FILE: Number of bytes read=653050
		FILE: Number of bytes written=1749879
		FILE: Number of read operations=0
		FILE: Number of large read operations=0
		FILE: Number of write operations=0
		HDFS: Number of bytes read=618040
		HDFS: Number of bytes written=624269
		HDFS: Number of read operations=8
		HDFS: Number of large read operations=0
		HDFS: Number of write operations=2
		HDFS: Number of bytes read erasure-coded=0
	Job Counters
		Launched map tasks=1
		Launched reduce tasks=1
		Data-local map tasks=1
		Total time spent by all maps in occupied slots (ms)=5408
		Total time spent by all reduces in occupied slots (ms)=6540
		Total time spent by all map tasks (ms)=2704
		Total time spent by all reduce tasks (ms)=3270
		Total vcore-milliseconds taken by all map tasks=2704
		Total vcore-milliseconds taken by all reduce tasks=3270
		Total megabyte-milliseconds taken by all map tasks=1384448
		Total megabyte-milliseconds taken by all reduce tasks=1674240
	Map-Reduce Framework
		Map input records=4058
		Map output records=5533
		Map output bytes=639356
		Map output materialized bytes=653050
		Input split bytes=116
		Combine input records=5533
		Combine output records=5502
		Reduce input groups=5502
		Reduce shuffle bytes=653050
		Reduce input records=5502
		Reduce output records=5502
		Spilled Records=11004
		Shuffled Maps =1
		Failed Shuffles=0
		Merged Map outputs=1
		GC time elapsed (ms)=132
		CPU time spent (ms)=1720
		Physical memory (bytes) snapshot=535298048
		Virtual memory (bytes) snapshot=4670066688
		Total committed heap usage (bytes)=406323200
		Peak Map Physical memory (bytes)=296005632
		Peak Map Virtual memory (bytes)=2333917184
		Peak Reduce Physical memory (bytes)=239292416
		Peak Reduce Virtual memory (bytes)=2336149504
	Shuffle Errors
		BAD_ID=0
		CONNECTION=0
		IO_ERROR=0
		WRONG_LENGTH=0
		WRONG_MAP=0
		WRONG_REDUCE=0
	File Input Format Counters
		Bytes Read=617924
	File Output Format Counters
		Bytes Written=624269
```
### yarn


### hive
#### DDL
- 创建
```
CREATE EXTERNAL TABLE ods.user (
  user_num STRING COMMENT '用户编号',
  mobile STRING COMMENT '手机号码',
  reg_date STRING COMMENT '注册日期'
COMMENT '用户资料表'
PARTITIONED BY (dt string)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' LINES TERMINATED BY '\n'
STORED AS ORC
LOCATION '/ods/user';
)
```
#### 拉链表
- 概念
```
通过数据结束时间来确定数据是否为最新记录，默认结束时间为最大时间，如果数据有修改，设置数据结束时间为修改时间，修改后数据的新增时间为修改时间，结束时间为最大时间
```
- 应用场景
```
在数据仓库的数据模型设计过程中，经常会遇到下面这种表的设计：

有一些表的数据量很大，比如一张用户表，大约10亿条记录，50个字段，这种表，即使使用ORC压缩，单张表的存储也会超过100G，在HDFS使用双备份或者三备份的话就更大一些。
表中的部分字段会被update更新操作，如用户联系方式，产品的描述信息，订单的状态等等。
需要查看某一个时间点或者时间段的历史快照信息，比如，查看某一个订单在历史某一个时间点的状态。
表中的记录变化的比例和频率不是很大，比如，总共有10亿的用户，每天新增和发生变化的有200万左右，变化的比例占的很小。
那么对于这种表我该如何设计呢？下面有几种方案可选：

方案一：每天只留最新的一份，比如我们每天用Sqoop抽取最新的一份全量数据到Hive中。
方案二：每天保留一份全量的切片数据。
方案三：使用拉链表。
```
- 设计和实现
```
1. ODS层原始切片表（按天分区，包含更新时间）
2. 加工更新表（包含新增和被修改的数据）
3. INSERT OVERWRITE TABLE dws.table
   SELECT * FROM
   (
       SELECT A.user_num,
              A.mobile,
              A.reg_date,
              A.t_start_time,
              CASE
                   WHEN A.t_end_time = '9999-12-31' AND B.user_num IS NOT NULL THEN '2017-01-01'
                   ELSE A.t_end_time
              END AS t_end_time
       FROM dws.user_his AS A
       LEFT JOIN ods.user_update AS B
       ON A.user_num = B.user_num
   UNION
       SELECT C.user_num,
              C.mobile,
              C.reg_date,
              '2017-01-02' AS t_start_time,
              '9999-12-31' AS t_end_time
       FROM ods.user_update AS C
   ) AS T
```
- 冷热数据分离
```
因为拉链表会保存历史全量变更，数据量会不断增加，可以抽取最近一段时间的变更数据供后面使用
```

### hbase

- Phoenix

### spark
- scala match
- scala容器

- scala隐式转换

- scala偏函数

- scala特质

- spark rdd dataframe dataset区别和转换

- spark shuffle stage
```
reduceByKey、groupByKey、countByKey、join等操作会产生shuffle
# 开启map端输出文件合并
spark.shuffle.consolidateFiles # 默认为false，设置为true，那么就会开启consolidate机制，会大幅度合并shuffle write的输出文件
new SparkConf().set("spark.shuffle.consolidateFiles", "true")
# shuffle缓存调整
spark.shuffle.file.buffer # 设置shuffle write task的BufferedOutputStream的buffer缓冲大小，默认32k
spark.reducer.maxSizeInFlight # 设置shuffle read task的buffer缓冲大小，而这个buffer缓冲决定了每次能够拉取多少数据
spark.shuffle.memoryFraction # 设置Executor内存中，分配给shuffle read task进行聚合操作的内存比例，默认是0.2
spark.shuffle.manager # 默认值：sort，设置ShuffleManager的类型。Spark 1.5以后，有三个可选项：hash、sort和tungsten-sort。
                        通过bypass机制（spark.shuffle.sort.bypassMergeThreshold大于shuffle read task的数量。那么此时就会自动启用bypass机制）或优化的HashShuffleManager来避免排序操作
```
- spark常用算子
map flatmap

-spark partition

- spark-submit 调优参数

- spark 内存溢出

- spark cache persist

- spark数据倾斜


### Storm
https://blog.csdn.net/vim_wj/article/details/75831677
### impala

### kafka


### zookeeper


### elasticsearch


### flume


### ranger


### Flink


### Kylin

### MQ
#### rabbitMQ
a)消费者是无法订阅或者获取不存在的MessageQueue中信息。
b)消息被Exchange接受以后，如果没有匹配的Queue，则会被丢弃。
- exchange
```
Exchange是接受生产者消息并将消息路由到消息队列的关键组件。ExchangeType和Binding决定了消息的路由规则。所以生产者想要发送消息，首先必须要声明一个Exchange和该Exchange对应的Binding。
可以通过 ExchangeDeclare和BindingDeclare完成。在Rabbit MQ中，声明一个Exchange需要三个参数：ExchangeName，ExchangeType和Durable。
ExchangeName是该Exchange的名字，该属性在创建Binding和生产者通过publish推送消息时需要指定。ExchangeType，指Exchange的类型，在RabbitMQ中，有三种类型的Exchange：direct ，fanout和topic，不同的Exchange会表现出不同路由行为。
Direct类型，则会将消息中的RoutingKey与该Exchange关联的所有Binding中的BindingKey进行比较，如果相等，则发送到该Binding对应的Queue中。
Fanout  类型，则会将消息发送给所有与该  Exchange  定义过  Binding  的所有  Queues  中去，其实是一种广播行为。
Topic类型，则会按照正则表达式，对RoutingKey(生产者)与BindingKey(bind指定)进行匹配，如果匹配成功，则发送到对应的Queue中。
```
- Binding
```
声明一个Binding需要提供一个QueueName，ExchangeName和BindingKey。
```
- queue


### java
- 集合

- 高并发


- 垃圾收集

- ClassLoader

- maven
# -pl指定打包模块  -am同时install依赖
mvn clean install -Dmaven.test.skip=true -pl data-insight-manage -am
mvn clean install -Dmaven.test.skip=true -rf data-insight-manage
```
双亲委派
web容器需要自定义classloader，实现不同项目之间class隔离
```
- 内存模型

### netty


### spring cloud

- dubbo


### k8s+docker
- docker文章
```
http://www.cnblogs.com/SzeCheng/p/6822905.html
```
- Dockerfile配置
1.vim Dockerfile
```
FROM centos:6
# ADD可以自动解压缩
ADD jdk1.8.tar.gz /opt/
ENV JAVA_HOME=
ENV CLASS_PATH=.:$JAVA_HOME/lib:$CLASS_PATH \
PATH=$JAVA_HOME/bin:$PATH
ENV LANG en_US.utf8
```
2.docker build -t jdk:8 -f Dockerfile .

- docker 常用操作
```
# 启动新容器
docker run -itd --name jdk jdk:8 /bin/bash
docker run --name web2 -d -p 81:80 nginx:v2
# 进入运行中的容器
docker exec -it jdk bash
# 停止后台容器
docker container ls -a
docker container stop jdk
# 重启已停止容器
docker container start jdk
# 删除容器
docker container rm jdk
```
- docker安装
```

```


### mybatis

- 拦截器


#### 算法
- 图

- bitmap

- hash

- 树

- 排序

- 背包

### redis
- redis value size
```
通信缓冲区的最终限制。
当GET命令应用于大对象时，首先序列化该对象
在通信缓冲区中，然后写入客户端套接字。
最理想的情况是在一个以太网数据（1500byte）包内传输
```
### mysql
#### Canal日志同步

### 缓存
