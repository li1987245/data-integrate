### hadoop


### yarn


### hive
#### DDL
- 创建
```
CREATE EXTERNAL TABLE ods.user (
  user_num STRING COMMENT '用户编号',
  mobile STRING COMMENT '手机号码',
  reg_date STRING COMMENT '注册日期'
COMMENT '用户资料表'
PARTITIONED BY (dt string)
ROW FORMAT DELIMITED FIELDS TERMINATED BY '\t' LINES TERMINATED BY '\n'
STORED AS ORC
LOCATION '/ods/user';
)
```
#### 拉链表
- 概念
```
通过数据结束时间来确定数据是否为最新记录，默认结束时间为最大时间，如果数据有修改，设置数据结束时间为修改时间，修改后数据的新增时间为修改时间，结束时间为最大时间
```
- 应用场景
```
在数据仓库的数据模型设计过程中，经常会遇到下面这种表的设计：

有一些表的数据量很大，比如一张用户表，大约10亿条记录，50个字段，这种表，即使使用ORC压缩，单张表的存储也会超过100G，在HDFS使用双备份或者三备份的话就更大一些。
表中的部分字段会被update更新操作，如用户联系方式，产品的描述信息，订单的状态等等。
需要查看某一个时间点或者时间段的历史快照信息，比如，查看某一个订单在历史某一个时间点的状态。
表中的记录变化的比例和频率不是很大，比如，总共有10亿的用户，每天新增和发生变化的有200万左右，变化的比例占的很小。
那么对于这种表我该如何设计呢？下面有几种方案可选：

方案一：每天只留最新的一份，比如我们每天用Sqoop抽取最新的一份全量数据到Hive中。
方案二：每天保留一份全量的切片数据。
方案三：使用拉链表。
```
- 设计和实现
```
1. ODS层原始切片表（按天分区，包含更新时间）
2. 加工更新表（包含新增和被修改的数据）
3. INSERT OVERWRITE TABLE dws.table
   SELECT * FROM
   (
       SELECT A.user_num,
              A.mobile,
              A.reg_date,
              A.t_start_time,
              CASE
                   WHEN A.t_end_time = '9999-12-31' AND B.user_num IS NOT NULL THEN '2017-01-01'
                   ELSE A.t_end_time
              END AS t_end_time
       FROM dws.user_his AS A
       LEFT JOIN ods.user_update AS B
       ON A.user_num = B.user_num
   UNION
       SELECT C.user_num,
              C.mobile,
              C.reg_date,
              '2017-01-02' AS t_start_time,
              '9999-12-31' AS t_end_time
       FROM ods.user_update AS C
   ) AS T
```
- 冷热数据分离
```
因为拉链表会保存历史全量变更，数据量会不断增加，可以抽取最近一段时间的变更数据供后面使用
```

### hbase

- Phoenix

### spark
- scala match
- scala容器

- scala隐式转换

- scala偏函数

- scala特质

- spark rdd dataframe dataset区别和转换

- spark suff stage

- spark常用算子
map flatmap

-spark partition

- spark-submit 调优参数

- spark 内存溢出

- spark cache persist

- spark数据倾斜


### Storm
https://blog.csdn.net/vim_wj/article/details/75831677
### impala

### kafka


### zookeeper


### elasticsearch


### flume


### ranger


### Flink


### Kylin

### MQ
#### rabbitMQ
a)消费者是无法订阅或者获取不存在的MessageQueue中信息。
b)消息被Exchange接受以后，如果没有匹配的Queue，则会被丢弃。
- exchange
```
Exchange是接受生产者消息并将消息路由到消息队列的关键组件。ExchangeType和Binding决定了消息的路由规则。所以生产者想要发送消息，首先必须要声明一个Exchange和该Exchange对应的Binding。
可以通过 ExchangeDeclare和BindingDeclare完成。在Rabbit MQ中，声明一个Exchange需要三个参数：ExchangeName，ExchangeType和Durable。
ExchangeName是该Exchange的名字，该属性在创建Binding和生产者通过publish推送消息时需要指定。ExchangeType，指Exchange的类型，在RabbitMQ中，有三种类型的Exchange：direct ，fanout和topic，不同的Exchange会表现出不同路由行为。
Direct类型，则会将消息中的RoutingKey与该Exchange关联的所有Binding中的BindingKey进行比较，如果相等，则发送到该Binding对应的Queue中。
Fanout  类型，则会将消息发送给所有与该  Exchange  定义过  Binding  的所有  Queues  中去，其实是一种广播行为。
Topic类型，则会按照正则表达式，对RoutingKey(生产者)与BindingKey(bind指定)进行匹配，如果匹配成功，则发送到对应的Queue中。
```
- Binding
```
声明一个Binding需要提供一个QueueName，ExchangeName和BindingKey。
```
- queue


### java
- 集合

- 高并发


- 垃圾收集

- ClassLoader
```
双亲委派
web容器需要自定义classloader，实现不同项目之间class隔离
```
- 内存模型

- nio
FileLock可以实现不同jvm进程之间的文件锁，不能实现同一jvm多线程文件锁，同jvm多线程会抛java.nio.channels.OverlappingFileLockException异常
WatchService可以监控文件
### netty


### spring cloud

- dubbo


### k8s+docker
- docker文章
```
http://www.cnblogs.com/SzeCheng/p/6822905.html
```
- Dockerfile配置
1.vim Dockerfile
```
FROM centos:6
# ADD可以自动解压缩
ADD jdk1.8.tar.gz /opt/
ENV JAVA_HOME=
ENV CLASS_PATH=.:$JAVA_HOME/lib:$CLASS_PATH \
PATH=$JAVA_HOME/bin:$PATH
ENV LANG en_US.utf8
```
2.docker build -t jdk:8 -f Dockerfile .

- docker 常用操作
```
# 启动新容器
docker run -itd --name jdk jdk:8 /bin/bash
docker run --name web2 -d -p 81:80 nginx:v2
# 进入运行中的容器
docker exec -it jdk bash
# 停止后台容器
docker container ls -a
docker container stop jdk
# 重启已停止容器
docker container start jdk
# 删除容器
docker container rm jdk
```
- docker安装
```

```


### mybatis

- 拦截器


#### 算法
- 图

- bitmap

- hash

- 树

- 排序

- 背包

### redis
- redis value size
```
通信缓冲区的最终限制。
当GET命令应用于大对象时，首先序列化该对象
在通信缓冲区中，然后写入客户端套接字。
最理想的情况是在一个以太网数据（1500byte）包内传输
```
### mysql
#### Canal日志同步

### 缓存
